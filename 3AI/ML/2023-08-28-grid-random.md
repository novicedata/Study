---
excerpt: "Grid search, Random searchμ— λ€ν•΄ μ•μ•„λ³΄μ."

categories:
  - Machine learning

tags:
  - [νμ΄μ¬, μµμ ν™”]

toc: true
toc_sticky: true

breadcrumb: true

date: 2023-08-28
last_modified_at: 2023-08-28

title: "[Machine learning, Python] κ·Έλ¦¬λ“ μ„μΉ(Grid search), λλ¤ μ„μΉ(Random search)μ— λ€ν•΄μ„, νμ΄μ¬ μ½”λ“"
---
<br>

# π“ Grid search vs Random Search
---

- **κ·Έλ¦¬λ“ μ„μΉ(Grid search)**
  
  ν•μ΄νΌ νλΌλ―Έν„°λ¥Ό μ—¬λ¬ κ°’μ„ μ§€μ •ν•΄μ£Όμ–΄ κ° κ°’μ μ΅°ν•©λ“¤μ„ **`λ¨λ‘`** ν™•μΈν•μ—¬ κ°’μ„ λΉ„κµν•λ” λ°©μ‹μΌλ΅ μ‘λ™ν•©λ‹λ‹¤.
  
  **`λ‹¨μ `**μ΄ ν™•μ‹¤ν•©λ‹λ‹¤. μ°μ„  **κ°€μ¥ μµμ μ νλΌλ―Έν„°λ¥Ό μ°Ύλ”λ‹¤λ” λ³΄μ¥μ΄ μ—†μµλ‹λ‹¤.** κ²°κµ­ λ¨λΈμ„ κµ¬μ„±ν•  λ• μ—¬λ¬ νλΌλ―Έν„°λ¥Ό λ„£μ–΄μ£Όλ” κ²ƒμ€ λ¨λΈμ„ λ§λ“λ” μ‚¬λμ΄κΈ° λ•λ¬Έμ— μ‹¤μ λ΅ κ°€μ¥ μµμ μ νλΌλ―Έν„°λ¥Ό λ„£μ–΄ μ£Όμ§€ λ»ν•λ‹¤λ©΄ λ‹Ήμ—°ν μ–΄λ μ΅°ν•©μΌλ΅λ„ κ°€μ¥ μµμ μ μ΅°ν•©μ„ μ°Ύμ•„μ£Όμ§€ λ»ν•©λ‹λ‹¤. κ·Έμ € λ³΄μΈμ΄ λ„£μ€ νλΌλ―Έν„°λ“¤μ μ΅°ν•©μ„ μ΄μ©ν•΄μ„ μµμ μ μ΅°ν•©μ„ μ°Ύμ•„μ£Όλ” κ²ƒμ΄μ£ .
  λν•, **μ“Έλ° μ—†λ” νλΌλ―Έν„° μ΅°ν•©μ„ λ¨λ‘ ν™•μΈν•©λ‹λ‹¤.** κ²°κµ­ λ¨λ“  μ΅°ν•©μ„ κ³„μ‚°ν•κΈ° λ•λ¬Έμ— μµμ μ κ°’μ—μ„ λ¨Ό κ±°λ¦¬μ— μλ” μ΅°ν•©λ„ ν™•μΈν•΄μ•Όν•©λ‹λ‹¤. μ΄λ” **`μμ› μ†λ¨κ°€ μ‹¬ν•λ‹¤`** λΌλ” λ‹¨μ κ³Ό μ§κ²°λ©λ‹λ‹¤. μ‹κ°„μ΄ μ •λ§~~~~ μ¤λ κ±Έλ¦½λ‹λ‹¤.
  
  ν•΄λ³΄μ‹  λ¶„λ“¤μ€ μ•κ² μ§€λ§, μ΅°ν•©μ„ μ΅°κΈλ§ λλ ¤λ„ μ‹κ°„μ΄ μ½”λ“λ¥Ό λλ¦¬λ”λ° μ‹κ°„μ΄ λ„λ¬΄ μ¤λκ±Έλ¦½λ‹λ‹¤.
  
- **λλ¤ μ„μΉ(Random search)**
  
  μ£Όμ–΄μ§„ ν•μ΄νΌ νλΌλ―Έν„° λ²”μ„ μ•μ—μ„ **λλ¤μΌλ΅** λ½‘μ•„μ„ κ°’μ„ λΉ„κµν•©λ‹λ‹¤. κ·Έλ¦¬λ“ μ„μΉμ™€λ” λ‹¤λ¥΄κ² κµ¬κ°„κ³Ό μ‹λ„ νμλ¥Ό μ§€μ •ν•΄μ£Όλ©΄, λλ¤μΌλ΅ μ§„ν–‰ν•΄μ¤λ‹λ‹¤.
  
  **`μ¥μ `**μ΄λΌ ν•λ©΄, μ°μ„  κ·Έλ¦¬λ“ μ„μΉλ³΄λ‹¤ λ‹Ήμ—°ν **λΉ λ¦…λ‹λ‹¤.** μ§€μ •ν•΄μ¤€ νλΌλ―Έν„° μ΅°ν•©μ„ λ¨λ‘ μ‚¬μ©ν•λ”κ² μ•„λ‹κΈ° λ•λ¬Έμ— λΉ λ¥΄κ³  ν¨μ¨μ μ…λ‹λ‹¤. **`λ‹¨μ `**μ΄λΌ ν•λ©΄ κ·Έλ¦¬λ“ μ„μΉμ™€ λΉ„μ·ν•κ² λλ¤μ΄λΌλ„ κ²°κµ­ μµμ μ νλΌλ―Έν„°λ¥Ό λ»μ°Ύμ„ κ°€λ¥μ„±μ΄ μ΅΄μ¬ν•λ‹¤λ” μ  μ •λ„κ² λ„¤μ”.
  
<br>

## β—Ύ κ·Έλ¦¬λ“ μ„μΉ in Python (Gride search code)

λ°μ΄ν„°λ” iris, λ¨λΈμ„ xgboostλ¥Ό μ΄μ©ν–μµλ‹λ‹¤.

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score
import xgboost as xg

# λ°μ΄ν„° λ¶λ¬μ¤κΈ°
iris = load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
xg_train = xg.DMatrix(data=X_train, label=y_train)
xg_test = xg.DMatrix(data=X_test, label=y_test)

# xgboost λ¨λΈ μ„¤μ •
model = xg.XGBClassifier(objective='multi:softmax', num_class=3)
```

xgboostλ¥Ό μ„ν•΄ DMatrixμ— λ§μ¶”μ–΄ λ°μ΄ν„°λ¥Ό κµ¬μ„±ν•κ³  λ‹¤μ¤‘ λ¶„λ¥μ΄κΈ° λ•λ¬Έμ— **`multi:softmax`**λ¥Ό μ§€μ •ν•΄μ¤μ‹λ‹¤.(κ·Όλ° ν•κ³  λ‚μ„ λ³΄λ‹κΉ μ•μ•„μ„ μ§€μ •λμ–΄ μ£Όλ”κ±° κ°™μ•„μ”. μ²μμ— μ¤νƒ€λ‚¬λ”λ° μ‹¤ν–‰λμ.. κ²°κ³Όλ„ κ°™κ³ )

**κ·Έλ‹¤μ κ·Έλ¦¬λ“ μ„μΉλ¥Ό μ„ν•΄ XGboostμ νλΌλ―Έν„° κ°’λ“¤μ„ μ§€μ •ν•΄μ¤λ‹λ‹¤.**

```python
# κ·Έλ¦¬λ“ μ„μΉ νλΌλ―Έν„° μ •ν•κΈ°
param_grid={'n_estimators':[100, 200], # λ‚λ¬΄ κ°μ,
            'learning_rate':[0.01, 0.1], # ν•™μµλ¥ 
            'max_depth':[2,4], # λ‚λ¬΄ κΉμ΄
            'gamma':[0,1], # κ°€μ§€λ¥Ό μΉ μ§€ κ²°μ •ν•λ” μµμ†μ†μ‹¤κ°μ† μ΅°μ • κ°’. ν΄μλ΅ κ³Όμ ν•© κ°μ†
}
```

κ·ΈλΌ κ·Έλ¦¬λ“ μ„μΉλ” 2x2x2x2 μ΄ 16κ°μ μ΅°ν•©μ„ μ‚¬μ©ν•΄μ£Όλ” κ²λ‹λ‹¤. **`μ΄λ” μμ‹μΌ λΏ μ‹¤μ λ΅ μ°λ¦¬κ°€ λ¨λΈμ„ μ—°κµ¬ν•  λ•λ” λ”λ§μ€ μ΅°ν•©μ΄ μ‚¬μ©λμ–΄μ„ μ‹κ°„μ΄ μ—„μ²­ κ±Έλ¦½λ‹λ‹¤.`**

λ‹¤μ κ·Έλ¦¬λ“ μ„μΉ νλΌλ―Έν„°λ¥Ό μ„¤μ •ν•΄μ¤λ‹λ‹¤. cv=3μΌλ΅ cross validationμ„ 3μΌλ΅ μ§€μ •ν•΄μ¤€κ²λ‹λ‹¤.

```python
# κ·Έλ¦¬λ“ μ„μΉ νλΌλ―Έν„° μ„¤μ •
gcv=GridSearchCV(model, param_grid=param_grid, cv=3)
```

```python
# λ¨λΈ ν”Όν… λ° κ²°κ³Ό
gcv.fit(X_train,y_train)
result = gcv.best_params_
score = gcv.best_score_
print(result, score) 

>> {'gamma': 0, 'learning_rate': 0.01, 'max_depth': 2, 
    'n_estimators': 100} 0.9333333333333332
```

μ΄λ ‡κ² κ²°κ³Όλ¥Ό λ³΄μ—¬μ¤λ‹λ‹¤. μ΅°ν•©κ²°κ³Ό **κ°λ§ : 0, ν•™μµλ¥  : 0.01, λ‚λ¬΄ κΉμ΄ : 2, λ‚λ¬΄ κ°μ 100**μΌ λ• **0.933**μ μ„±λ¥μ„ λ³΄μ—¬μ¤λ‹λ‹¤.

κ·ΈλΌ test setλ¥Ό μ΄μ©ν•΄ μ •ν™•λ„λ¥Ό ν™•μΈν•΄λ³Όκ²μ”.

```python
# μµμ  νλΌλ―Έν„° ν•™μµ λ¨λΈ
best_model = gcv.best_estimator_

# λ¶„λ¥ μ„±λ¥ ν™•μΈ
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(accuracy) 

>> 0.933333333333
```

<br>

## β—Ύ λλ¤ μ„μΉ in Python (Random seach code)

λ”±ν ν¬κ² λ‹¬λΌμ§€λ” κ±΄ μ—†μµλ‹λ‹¤. **`λλ¤ μ„μΉλ¥Ό μ„ν• xgboostμ νλΌλ―Έν„° μ„¤μ •κ³Ό λλ¤ μ„μΉ νλΌλ―Έν„° μ„¤μ •λ§ λ°”κΏ”μ¤μ‹λ‹¤.`**

```python
from sklearn.model_selection import RandomizedSearchCV

# λλ¤ μ„μΉ νλΌλ―Έν„° μ •ν•κΈ°
param_dis={'n_estimators': np.arange(50,200), # λ‚λ¬΄ κ°μ,
            'learning_rate':[0.01, 0.5], # ν•™μµλ¥ 
            'max_depth':[2,4,6], # λ‚λ¬΄ κΉμ΄
            'gamma':[0,1], # κ°€μ§€λ¥Ό μΉ μ§€ κ²°μ •ν•λ” μµμ†μ†μ‹¤κ°μ† μ΅°μ • κ°’. ν΄μλ΅ κ³Όμ ν•© κ°μ†
}

# λλ¤ μ„μΉ νλΌλ―Έν„° μ„¤μ •
rcv=RandomizedSearchCV(model, param_distributions=param_dis,
                       n_iter=50, cv=3)
```

κ²°κ³Όλ¥Ό λ³΄λ©΄

```python
# λ¨λΈ ν”Όν… λ° κ²°κ³Ό
rcv.fit(X_train,y_train)
result = rcv.best_params_
score = rcv.best_score_
print(result, score) 

>> {'n_estimators': 192, 'max_depth': 2,
     'learning_rate': 0.5, 'gamma': 0} 0.9500000000000001
```

μ΄λ²μ—” **λ‚λ¬΄ κ°μ: 192, κΉμ΄ :2, ν•™μµλ¥  : 0.5, κ°λ§:0** μΌ λ• μ„±λ¥μ΄ **0.95**κ°€ λ‚μ¤λ„¤μ”. **`grid searchλ³΄λ‹¤ μ‚΄μ§ λ†’μµλ‹λ‹¤.`**

```python
# μµμ  νλΌλ―Έν„° ν•™μµ λ¨λΈ
best_model = rcv.best_estimator_

# λ¶„λ¥ μ„±λ¥ ν™•μΈ
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(accuracy) 

>> 0.9666666666666667
```

test setλ¥Ό μ΄μ©ν• μ •ν™•λ„ κ²°κ³Ό 0.966μ •λ„κ°€ λ‚μµλ‹λ‹¤. κ²°κ³Όμ μΌλ΅ grid search λ³΄λ‹¤ λ†’κ²λ‚μ¤λ„¤μ”!!

λ¬Όλ΅  λ°μ΄ν„°μ κµ¬μ΅°, νλΌλ―Έν„°λ¥Ό μ–΄λ–»κ² λ„£μ–΄μ£Όλλƒ λ“±μ— λ”°λΌ λ³€ν•  μλ” μμ§€λ§ grid searchμ λ”μ°ν• μ‹κ°„μ„ μƒκ°ν•λ©΄... random searchλ¥Ό μ“°λ”κ² μ•„μ§μ€ ν¨μ¨μ μΈ κ²ƒ κ°™μµλ‹λ‹¤..

**`νΉμ‹λ‚ ν‹€λ¦° λ¶€λ¶„μ— λ€ν•΄μ„λ” λ“κΈ€λ΅ λ‚¨κ²¨μ£Όμ„Έμ”!`**
