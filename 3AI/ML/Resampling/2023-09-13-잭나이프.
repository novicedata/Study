---
excerpt: "Jackknife에 대해 알아보자"

categories:
  - Resampling

tags:
  - [통계 분석]

toc: true
toc_sticky: true

breadcrumb: true

date: 2023-09-13
last_modified_at: 2023-09-13

title: "Jackknife, 잭나이프"
---

# 📌 Jackknife
---

**`Jackknife`**기법입니다. 우리에게는 leave-one-out과 비슷한 것으로 많이 알려져 있죠?

추정치의 편향을 감소시키기 위해 개발되었습니다. LOO처럼 데이터에서 한 번에 하나의 관측값을 제외하면서 통계량을 recompute하는 방법입니다. 이를 통해 우리는 통계량의 변동성(Variability)를 추정할 수 있습니다.

간단하게 어떤식으로 jackknife가 진행되는지 아주 간단하게 본다면.

1. 전체 데이터에 대해 원하는 통계량을 구합니다.
2. 전체 데이터 $n$에서 하나의 샘플을 뺀 $n-1$ 데이터의 통계량을 구합니다.
3. 이를 전체 샘플에서 반복하여 진행합니다. 그렇다면 **n개의 통계량이 나올 것이고 이를 통해 distribution을 만들고 확인할 수 있죠!**
  

이를 통해 resampling하는 것인데요. 1번에서 구한 전체 데이터의 통계량과 3을 통해 얻은 결과의 평균이 동일합니다.

`맨 위에서 추정치의 편향을 감소시키기 위해 개발되었다고 했습니다.`

그럼 jackknife 방법을 사용하여 편향을 추정하는 과정을 한번 봅시다.

- $f_n = f_n(X_1,...,X_n)$ : 우리가 모르는 모수 $\theta$의 추정값인 추정량
  

**이때, $f_n$의 편향의 경우 아래와 같습니다.**

$$
Bias(f_n) = E_\theta(f_n)-\theta
$$

*실제 모수와 추정값 평균의 차이입니다.*

- $f_{n-1,i} = f_{n-1}(X1,...,X_{i-1},X_{i+1},...X_n)$ : $X_i$ 관측값을 제외한 n-1개의 다른 관측값을 기반으로한 추정량(estimator)라고 합시다.
  

**이 때, $f_{n-1,i}$의 평균은 아래와 같습니다.**

$$
\bar{f}_n = \frac1n \sum^n_{k=1}f_{n-1,k}
$$

## `중요!`

만약 편향인 $bias(f_n) = \frac{a}{n} + e$ 라면($a$는 어떠한 상수입니다. **아래 처럼 편향식을 근사할 수 있습니다.**

$$
\begin{align}
&E(f_n)-\theta \approx \dfrac{a}{n}
\\ &E(\bar{f}_n) - \theta \approx \dfrac{a}{n-1}
\\ &E(\bar{f}_n - f_n) \approx \dfrac{a}{n(n-1)}
\end{align}
$$

여기서 **jackkinfe 편향 추정은 아래와 같습니다.** 이 식으로 jackknife 방법에서 편향을 추정하는데 사용합니다.

$$
jack = (n-1)(\bar{f}_n-f_n)
$$

자 여기서, **편향을 구했으니 이 값을 제거한 추정량을 얻어야 하죠**. 이 값을 아래와 같습니다.

$$
f_{jack} =f_n-jack = nf_n-(n-1)\bar{f}_n
$$

또한, **분산**도 구할 수 있습니다. 분산을 구하는 식을 도출하기 위해서 Tukey가 말했던 psedo-value까지 알아야하는데, 너무 길어것 같아서 식만 첨부하겠습니다.

$$
v_{jack} = \dfrac{n-1}{n} \sum^n_{i=1}(f_{n-1,i}-\frac1n \sum^n_{j=1}f_{n-1,j})^2
$$

> 참조 : [Jackknife resampling - Wikipedia](https://en.wikipedia.org/wiki/Jackknife_resampling), [(데이터과학 인터뷰 질문) (3) 샘플링과 리샘플링, 2편 : 잭나이핑과 부트스트래핑](https://cnp-0717.tistory.com/8)
