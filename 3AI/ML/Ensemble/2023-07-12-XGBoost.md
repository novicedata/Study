---

excerpt: "XGBoostì— ëŒ€í•´ì„œ ì•Œì•„ë³´ì"

categories:

- Machine learning

tags:

- [Boost]

toc: true
toc_sticky: true

breadcrumb: true

date: 2023-07-12
last_modified_at: 2023-07-12

title: "[Machine learning, ë¨¸ì‹ ëŸ¬ë‹] XGBoostì— ëŒ€í•´ì„œ(ì›ë¦¬ì™€ ê³µì‹)"

---

<br>

ì €ë²ˆ í¬ìŠ¤íŒ…ì— ì´ì–´ì„œ XGBoostì˜ ì›ë¦¬ì™€ ì™œ **`í™•ì¥ì„±`**ì´ ë†’ì€ ì•Œê³ ë¦¬ì¦˜ì¸ê°€ì— ëŒ€í•´ì„œ í¬ìŠ¤íŒ… í•˜ë ¤ê³  í•©ë‹ˆë‹¤!

ê³µì‹ì˜ ìœ ë„ì™€ ì›ë¦¬ì— ëŒ€í•œ ì´ì•¼ê¸°ì´ê¸° ë•Œë¬¸ì— ì „ í¬ìŠ¤íŒ…ì„ ë³´ê³  ì™€ì£¼ì„¸ìš”.

[[Machine learning, ë¨¸ì‹ ëŸ¬ë‹] XGBoost: A Scalable Tree Boosting System(Carlos &amp; Tianqi. 2016) ë¦¬ë·° - ë°ì´í„°ë¥¼ íŒŒê³ íŒŒëŠ” ì‚¬ëŒ â›ï¸](https://novicedata.github.io/machine%20learning/XGBoost-%EB%A6%AC%EB%B7%B0/)

<br>

# ğŸ“Œ XGBoost

---

ìš°ì„  **`XGBoost`**ë€ **ë¶€ìŠ¤íŒ…ì˜ í•œ ì¢…ë¥˜ë¡œ gradient boostingì˜ upgrade ë²„ì „ìœ¼ë¡œ ë³´ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤.** Gradient Boostingê³¼ ê°™ì´ ì”ì°¨ë¡œë¶€í„° í›ˆë ¨í•˜ë©° ì•½í•œ learnerë¥¼ ê°•í•œ learnerë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.(ì•™ìƒë¸” ëª¨í˜•)

í° íŠ¹ì§•ì´ë¼ë©´ **ë¹ ë¥¸ ì†ë„ì™€ ì„±ëŠ¥**ì´ë¼ê³  í•©ë‹ˆë‹¤.

<br>

# âš™ï¸ ì›ë¦¬ì™€ ê³µì‹ ìœ ë„

---

- n : data setë‚´ì˜ examples ìˆ˜
  
- m : examplesì•ˆì˜ ìš”ì¸ ìˆ˜
  
- D : nê°œì˜ example, ê° exampleì€ mê°œì˜ íŠ¹ì„±ì„ ì§€ë‹˜ (n x m)
  

ìœ„ì™€ ê°™ì€ ì¡°ê±´ì¼ ë•Œ DëŠ”

$$
D = {(x_i, y_i)} (|D| = n, x_i âˆˆ \mathbb{R}^m, y_i âˆˆ \mathbb{R})
$$

ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•´ë´…ì‹œë‹¤.

## 1ï¸âƒ£ ì•™ìƒë¸” ëª¨ë¸ ê¸°ë°˜

XGBoostëŠ” ì•™ìƒë¸” ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ, Kê°œì˜ ê°€ë²• í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ outputì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì‰½ê²Œ ì„¤ëª…í•˜ë©´ **ì—¬ëŸ¬ê°œì˜ íŠ¸ë¦¬ë¥¼ í•©ì¹œ ê²ƒì„ ì´ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.** ì‹ìœ¼ë¡œ í‘œì‹œí•˜ë©´ **ê²°ê³¼ = íŠ¸ë¦¬ì˜ í•©ë“¤**

$$
Eq(1) : 
\hat{y}_i = \phi(x_i) = \sum^K_{k=1} f_k(x_i), f_k\in \mathcal{F}
$$

- K : íŠ¸ë¦¬ì˜ ê°œìˆ˜
  
- $f$ : tree($\mathcal{F}$ì— ì†í•˜ëŠ” í•¨ìˆ˜)
  
- $\mathcal{F}$ : í•¨ìˆ˜ê³µê°„ìœ¼ë¡œ ëª¨ë“  ê°€ëŠ¥í•œ íŠ¸ë¦¬ì˜ ì§‘í•©
  

$$
\mathcal{F} = \{f(x) = w_{q(x)}\}(q : \mathbb{R}^m â†’ T, w âˆˆ \mathbb{R}^
T
)
$$

- $w$ : íŠ¸ë¦¬ì˜ leafì—ì„œì˜ ì ìˆ˜ ë²¡í„°
  
- $q$ : ë°ì´í„° í¬ì¸íŠ¸ë¥¼ í•´ë‹¹í•˜ëŠ” ë¦¬í”„ì— í• ë‹¹í•˜ëŠ” í•¨ìˆ˜
  
- $T$ : leafì˜ ìˆ˜
  

## 2ï¸âƒ£ ìµœì í™”í•´ì•¼í•˜ëŠ” ì •ê·œí™”ëœ ëª©ì  í•¨ìˆ˜

ìš°ì„  ëª©ì í•¨ìˆ˜ë¥¼ ë´…ì‹œë‹¤. ëª©ì í•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ì´ **ì†ì‹¤í•¨ìˆ˜ + ì •ê·œí™”í•­**ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.

$$
Eq(2). \ \mathcal{L}(\phi) = \sum_il(y_i,\hat{y}_i) + \sum_k\Omega(f_k)
\\
where\ \Omega(f) = \gamma T + \frac12 \lambda||w||^2
$$

ì •ê·œí™”í•­ì¸ $\Omega(f)$ì˜ ë‹¤ì–‘í•œ ì •ì˜ê°€ ìˆì§€ë§Œ í•´ë‹¹ì‹ì´ ê°€ì¥ ì¢‹ë‹¤ê³  í•˜ë„¤ìš”.

ì•ì„œ XGBoostëŠ” **Gradient boosting**ì˜ ì—…ê·¸ë ˆì´ë“œ ë²„ì „ì´ë¼ê³  í•˜ì˜€ìŠµë‹ˆë‹¤. ëª©ì í•¨ìˆ˜ì— **`Gradient Tree Boosting`**ì„ ì ìš©í•´ë´…ì‹œë‹¤.(**$\hat{y}_i^{(t)} = \hat{y}_i^{(t-1)} + f_t(x_i)$**)

$t$ë²ˆì§¸ íŠ¸ë¦¬ì—ì„œì˜ ëª©ì í•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$
\mathcal{L}^{(t)} = \sum^n_{i =1}l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) + \Omega(f_t) + \text{constant}
$$

ì—¬ê¸°ì„œ ìš°ë¦¬ì—ê²Œ ì¹œìˆ™í•œ í‰ê· ì œê³±ì˜¤ì°¨(MSE)ë¥¼ ì†ì‹¤í•¨ìˆ˜ë¡œ ì‚¬ìš©í•œë‹¤ë©´? í•´ë‹¹ ëª©ì í•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ê²Œ ë©ë‹ˆë‹¤.

$$
\begin{split}\mathcal{L}^{(t)} & = \sum_{i=1}^n (y_i - (\hat{y}_i^{(t-1)} + f_t(x_i)))^2 + \sum_{i=1}^t\Omega(f_i) \\          & = \sum_{i=1}^n [2(\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \Omega(f_t) + \mathrm{constant}\end{split}
$$

ìœ„ ì‹ì€ 1ì°¨í•­ê³¼ 2ì°¨í•­ì„ ê°€ì§€ë©° ê¹”ë”í•œ í˜•ì‹ì„ ë³´ì…ë‹ˆë‹¤ ë¬¸ì œëŠ” **ë‹¤ë¥¸ ì†ì‹¤í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ê²½ìš° ì´ì™€ê°™ì´ ê³„ì‚°í•˜ê¸° ì¢‹ì€ í˜•íƒœë¥¼ ê°€ì§€ê¸° ì–´ë µìŠµë‹ˆë‹¤.**

ê·¸ë˜ì„œ ìš°ë¦¬ëŠ” **`íƒœì¼ëŸ¬ ì „ê°œì˜ 2ì°¨ìˆ˜ê¹Œì§€ ì·¨í•˜ì—¬ ê¸°ì¡´ ëª©ì í•¨ìˆ˜ë¥¼ ê·¼ì‚¬í•©ë‹ˆë‹¤.`**

## 3ï¸âƒ£ íƒœì¼ëŸ¬ 2ì°¨ ê·¼ì‚¬ ëª©ì í•¨ìˆ˜

íƒœì¼ëŸ¬ ì „ê°œì˜ 2ì°¨ìˆ˜ ê¹Œì§€ ì·¨í•˜ì—¬ ëª©ì í•¨ìˆ˜ë¥¼ ê·¼ì‚¬í•œ ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$
\mathcal{L}^{(t)} \cong \sum_{i=1}^n [l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t) + \mathrm{constant}
$$

$$
\begin{split}g_i &= \partial_{\hat{y}_i^{(t-1)}} l(y_i, \hat{y}i^{(t-1)})
\\
h_i &= \partial_{\hat{y}_i^{(t-1)}}^2 l(y_i, \hat{y}_i^{(t-1)})\end{split}
$$

$g_i, h_i$ë¥¼ ë³´ì‹œë©´ ì•„ì‹œê² ì§€ë§Œ, ì´ëŠ” 1ì°¨ ê·¸ë ˆë””ì–¸íŠ¸ê°’, 2ì°¨ ê·¸ë ˆë””ì–¸íŠ¸ê°’ì…ë‹ˆë‹¤!

ì—¬ê¸°ì„œ ê·¼ì‚¬ì— í•„ìš”ì—†ëŠ” ìƒìˆ˜í•­ì„ ì œê±°í•œë‹¤ë©´

$$
Eq.(3). \ \tilde{\mathcal{L}}^{(t)} = \sum^n_{i =1}[g_if_t(x_i) + \frac12h_if_t^2(x_i)] + \Omega(f_t)
$$

ì—¬ê¸°ì„œ `Eq(2)`ì˜ ì •ê·œí™”í•­ì„ ëŒ€ì…í•˜ê³ , $I = \\{i\|q(x_i) = j\\}$(íŠ¸ë¦¬êµ¬ì¡° qì—ì„œ ë¦¬í”„ ë…¸ë“œ jì˜ ì¸ìŠ¤í„´ìŠ¤ ì§‘í•©)ë¡œ ì •ì˜í•˜ì—¬ ëŒ€ì…í•˜ë©´

$$
Eq.(4). \ \tilde{\mathcal{L}}^{(t)} = \sum^n_{i =1}[g_if_t(x_i) + \frac12h_if_t^2(x_i)] + \gamma T + \frac12 \lambda\sum_{j=1}^Tw_j^2
\\
= \sum_{j=1}^T[(\sum_{iâˆˆI_j}g_i)w_j + \frac12(\sum_{iâˆˆI_j}h_i + \lambda)w_j^2] + \gamma T
$$

$G_j = \sum_{i \in I_j}g_i, H_j = \sum_{i \in I_j}h_i$ë¼ê³  ë‚˜íƒ€ë‚´ê³ , ìµœì ì˜ $w_j^*$ë¥¼ $-\dfrac{G_j}{H_j + \lambda}$ë¼ê³  ì •ì˜ í•˜ì—¬ ëŒ€ì…í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ìµœì¢…ì‹ì´ ë‚˜ì˜µë‹ˆë‹¤.

$$
Eq. (6). \ \tilde{\mathcal{L}}^{(t)}(q) = -\frac12\sum_{j=1}^T\frac{G_j^2}{H_j + \lambda} +  \gamma T
$$

## score í•¨ìˆ˜

`Eq(6)`ì¸ ëª©ì í•¨ìˆ˜ë¥¼ íŠ¸ë¦¬ êµ¬ì¡° qì˜ qualityë¥¼ ì¸¡ì •í•˜ëŠ” scoreí•¨ìˆ˜ë¡œ ì´ìš©í•©ë‹ˆë‹¤. **ê°’ì´ ì‘ì„ìˆ˜ë¡ êµ¬ì¡°ê°€ ì¢‹ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.** ì™œëƒë©´ **ê·¸ë ˆë””ì–¸íŠ¸ ê°’ì¸ $g_i$ì— ìŒì˜ ê°’ì„ ì·¨í•œê²ƒì€** **ì”ì°¨**ë¼ê³  graident boostingì˜ ì›ë¦¬ì—ì„œ ì•Œ ìˆ˜ ìˆê³ , ì´ **`ì”ì°¨ê°€ í¬ë‹¤ëŠ” ê²ƒì€ ê·¸ë§Œí¼ ì˜ˆì¸¡ì„ ëª»í–ˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.`** ê·¸ë ‡ê¸° ë•Œë¬¸ì— ê°’ì´ ì‘ì„ìˆ˜ë¡ êµ¬ì¡°ê°€ ì¢‹ë‹¤ê³  ê²°ë¡ ì„ ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

![image](https://github.com/novicedata/scrap-comment/assets/88019539/9b676c05-bd3a-4ffb-a896-9df4fe8ad8ef)

## Greedy algorithm

ê·¸ëŸ°ë° ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ ë°©ë²•ì€ ê°€ëŠ¥í•œ ëª¨ë“  íŠ¸ë¦¬ êµ¬ì¡° që¥¼ ë³´ì•„ì•¼í•©ë‹ˆë‹¤. ì‚¬ì‹¤ìƒ ë¶ˆê°€ëŠ¥í•œ ì¼ì´ì£ . ê·¸ë˜ì„œ ë‹¨ì¼ leafì—ì„œ ì‹œì‘í•´ì„œ ë°˜ë³µì ìœ¼ë¡œ ê°€ì§€ë¥¼ ì¶”ê°€í•˜ëŠ” greedy algorithmì„ ì‚¬ìš©í•©ë‹ˆë‹¤. í•œê°€ì§€ì—ì„œ ë¶„í•  í›„ì˜ ì†ì‹¤ ê°ì†Œê°’ì„ ì°¾ì•„ ê°€ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

ì‹ì„ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$
L_{split} = \frac{1}{2} \left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] - \gamma
$$

ìœ„ ì‹ì€ ì–‘ì˜ ê°’ì´ë„¤ìš”. ì´ ê°’ì´ **ìµœëŒ€ì¸ ë³€ìˆ˜ì™€ ê·¸ì— ëŒ€ì‘í•˜ëŠ” ë¶„ë¦¬ ê¸°ì¤€ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.**

# âš“ ë§ˆì¹˜ë©°

---

ì´í•´í•˜ëŠ” ë° ì¡°ê¸ˆ ê±¸ë ¸ëŠ”ë°, ì—¬ëŸ¬ê°€ì§€ tutorialì„ ì°¾ì•„ë³´ê³  í™•ì‹¤íˆ êµ­ë‚´ë³´ë‹¤ëŠ” í•´ì™¸ ì—°êµ¬ê°€ ë§ì´ ë˜ì–´ìˆë‹¤ë³´ë‹ˆ.. í•´ì™¸ ê¸€ë“¤ ì°¾ì•„ë³´ë©´ ê¸ˆë°© ì´í•´í•  ìˆ˜ ìˆë”ë¼êµ¬ìš”. ì´í•´í•˜ê¸° ì‰¬ìš°ì…¨ìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.

**`ì´ìƒ XGBoostì˜ ì›ë¦¬ ì˜€ìŠµë‹ˆë‹¤! â˜ ï¸`**

> ì°¸ì¡°
> 
> [Introduction to Boosted Trees &mdash; xgboost 1.7.6 documentation](https://xgboost.readthedocs.io/en/stable/tutorials/model.html)
