---
excerpt: "베이지안 이론(Bayesian theory)에 대해 알아보자."

categories:
  - Statistics

tags:
  - [통계]

toc: true
toc_sticky: true

date: 2023-08-29
last_modified_at: 2023-08-29

title: "베이지안 이론(Bayesian theory)에 대해서"
---

<br>

**`베이지안 이론`**은 머신러닝에 있어서 아주 중요합니다. 보통 ML에서 쓰이는 데이터는 일반 확률론으로는 한계가 있고 ML자체가 특정 가성의 확률을 높이는 최적화된 모델을 찾는 것을 목적으로 하는 것이니까요.

<br>

# 📌 베이지안 vs 빈도주의
---

아마 베이지안에 대해 공부하시면 많이 들으셨을 주제 입니다. 정말 쉽게 설명해봅시다.

- **빈도주의**
  확률을 **`성공 횟수/전체 횟수의 극한`**으로 봅니다. 동일한 수행이 무한히 반복했을 때의 빈도를 말합니다. 말이 어렵지만 예를 들어봅시다. **동전 던지기**입니다. 우리는 당연하게도 앞면이 나올 확률 0.5, 뒷면이 나올 확률 0.5로 알고 있습니다. 왜 일까요? 동전은 5번 던졌을 때, 앞면이 4번이 나올수도 있습니다. 하지만 동전을 무수히 즉, **무한대로** 던지다보면 결국 0.5에 수렴하기 때문입니다. 
  우리가 아는 이 확률이 어찌보면 당연해보이지만 **`단점이 명확합니다.`** 어떠한 질병이 걸릴 확률이 0.02 이고 질병을 양성을로 판단할 확률이 0.9입니다. 한번 걸린 후 또다시 걸릴 확률을 구하면?.. 이는 **동일 조건에서 무한히 수렴하는 빈도 계산이 거의 불가능합니다.** 
  그렇다면 베이지안은 어떨까요?
  
- **베이지안**
  확률을 **`믿음의 정도`**라고 판단합니다. 쉽게 예를 들어 봅시다. **쟤 거짓말일 확률이 90%다 진짜.** 라고 말을 했습니다. 왜 일까요? 분명 그 대상자는 전에도 거짓말을 했을 경우가 많을 것입니다. 이러한 **`사전의 지식`**으로 확률을 구하는 것이죠.
  

<br>

# 📌 베이즈 정리(Bayes' theorem)
---

$$
P(H|D) = \dfrac{P(D|H)P(H)}{P(D)} \\ 사후 확률 = \dfrac{가능도 *사전확률}{데이터}
$$

로 나타납니다.

- **P(H\|D)** : 사후 확률. D가 발생했다는 조건에서 H가 발생했을 확률
- **P(D\|H)** : 가능도(우도). H가 발생했다는 조건에서 D가 발생했을 확률
- **P(H)** : 사전 확률. 결과 전에 이미 결정되었었던 H의 확률
  

한번 공식을 유도해보면

$$
P(H|D) = \dfrac{P(H \cap D)}{P(D)} \\ P(D|H) = \dfrac{P(D \cap H)}{P(H)} \\ P(H|D)P(D) = P(H \cap D) = P(D|H)P(H) \\ P(H|D) = \dfrac{P(D|H)P(H)}{P(D)}
$$

이렇게 되겠네요.

<br>

## ◾ 예제

위에서 말했던 예제를 확인해봅시다.

**"Peter가 A라는 병에 검사 결과 양성 판정을 받았습니다. 과연 Peter가 A에 걸린 것으로 나올 확률은 어떻게 될까요? 여기서 A병에 걸릴 확률이 `0.01`, 양성을 양성이라 판정할 확률은 `0.99`, 실제 음성인데 양성이라고 판정할 확률이 `0.1`."**

우리가 보아야할 **사후 확률**은 이렇게 정리 되겠네요.

$$
P(A병걸림|양성판정) = \dfrac{P(양성판정|A병걸림)*P(A병걸림)}{P(양성판정)}
$$

- P(양성 판정\|A병 걸림)**[가능도]** = 0.99 / P=(양성판정\|A병 안걸림) = 0.1
- P(A병 걸림)**[사전확률]** = 0.01 / P(A병 안걸림) = 0.99
- P(양성 판정)**[실제 데이터]** = A병 걸렸을 때 양성 판정 확률 + A병 안걸렸을 때 양성 판정 확률 = 0.99 * 0.01 + 0.1 * 0.99 = 0.1089
  

결과적으로 P(A병 걸림\|양성 판정) = (0.99 * 0.01) / 0.1089 대략 0.0909로 **`9.1%`** 정도의 적중률을 보입니다.
