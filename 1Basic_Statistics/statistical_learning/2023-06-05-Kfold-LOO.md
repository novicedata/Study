---
excerpt: "Leave-one-out과 K-fold에 대해 알아보자."

categories :
  - Statistical learning
tags :
  - [통계 학습]

toc: true
toc_sticky: true

date: 2023-05-30
last_modified_at: 2023-07-02

title: "Leave-one-out 교차 검증과 K-fold 교차 검증"
---
오늘은 교차검증을 주재로 포스팅을 하려고 합니다.

흔히 기계 학습을 할 때 우리는 타당도를 위해 교차검증을 합니다. 교차검증을 이해하기 위해 먼저 training set : 훈련 세트와 test set : 시험 세트를 이야기 해봅시다.

<br>

# Train set, Test set

---

**훈련 세트와 시험 세트**

우리가 특정 변수를 분류하기 위한 모델을 개발했다고 합니다. 이 모델이 얼마나 일반적으로 작동하는지 성능을 평가해야 합니다. 즉, **우리가 모델을 만드는데 사용한 데이터 뿐 아닌 다른 새로운 데이터에 대해서도 잘 작동하고 잘 분류하는지 알아야 합니다.**
**이를 위해 우리는 데이터 세트를 훈련 세트와 시험 세트로 나눕니다. **

데이터 세트를 임의로 두개 세트로 즉, 훈련 세트와 시험 세트로 나누어 성능을 평가합니다. 훈련 세트로 모델을 훈련시키고, 테스트 세트로는 성능을 평가합니다. 즉, *이미 훈련했던 세트로 훈련하지 않고 훈련에 사용하지 않은 시험 세트를 이용하여 마치 기존에 없던, 새로 생긴 데이터를 적용시키는 방식으로 보면 될 것 같습니다.*

![image](https://github.com/novicedata/colab_practice/assets/88019539/2d2d4752-dcf6-469e-94dd-63994e52db0f){: .align-center}


<br>

# 교차 검증(Cross Validation)
---

이렇게 쉬우면 좋겠지만? **실제로는 문제가 있습니다. 우선 데이터 세트가 너무 작을 경우 이러한 방법은 두 개의 세트를 어떻게 어느정도로 나누느냐에 따라서 결과가 매우 다를 수 있습니다. **

예를 들어 훈련 세트에는 분류하기 쉬운 샘플들이, 시험 세트에는 어려운 샘플들이 들어간다면? 훈련시킨 모델을 시험 세트에 적용한다면 쉽게 분류해내지 못하겠죠.
이러한 문제를 해결하기 위해 교차 검증을 사용합니다. 데이터 세트를 단 한 번만 나누어 훈련시키고 테스트하는 것이 아니라, 이를 반복하여 성능을 평균화하는 것입니다. 이렇게 진행 한다면 단 한번의 우연에 의한 결과 분산보다는 더욱 작아지겠죠. 그렇다면 *두 가지 방법인 K-fold cross validation과 leave-one-out 방법을 봅시다.*

<br>

## 📌 K-fold

**K-fold 교차 검증은 먼저 데이터 세트를 k개의 동일한 크기로 나누어 하위 세트를 생성합니다.**

![image](https://github.com/novicedata/colab_practice/assets/88019539/e0a9612f-c5b2-4a82-9221-0235df2d6546){: .align-center}

그리고 k번 반복하여 각각 k개의 하위 세트중에 하나의 세트를 테스트 세트로 사용하고 나머지를 훈련 세트로 이용합니다.
그리고 k번 시행한 점수를 평균화하여 모델 성능을 봅니다. 
예를 들어보죠 우리가 가진 데이터가 {a, b, c, d, e, f}가 있다고 합니다. 3-fold 교차 검증을 한다면

**set1 = {a, b}**

**set2 = {c, d}**

**set3 = {e, f}**

위와 같이 3개의 하위 세트로 나눕니다. (세트가 {a, f}등등 될 수도 있습니다. 보기 편하도록 알파벳 순서로 한 것입니다)

그리고 이 중 **하나의 세트를 시험 세트로 이용합니다. 시험 세트를 바꿔가며 k번(여기서는 3) 반복하는 것입니다.**

**시행 1 : 훈련 세트 = set1, set2 / 시험 세트 = set3**

**시행 2 : 훈련 세트 = set1, set3 / 시험 세트 = set2**

**시행 3 : 훈련 세트 = set2, set3 / 시험 세트 = set1**

그 후 3번의 시행으로 얻은 3개의 성능 점수를 평균화 하는 것입니다.

<br>

## 📌 Leave-one-out

**Leave-one-out 교차 검증에서는 데이터 세트 크기인 n. n 만큼 훈련합니다. 이름 처럼 단 하나의 샘플만을 테스트 세트로 사용하고 나머지를 훈련세트로 이용합니다.**

![image](https://github.com/novicedata/colab_practice/assets/88019539/14b39967-3d33-4c9e-9a72-89a6f11302d1){: .align-center}

위의 예시를 이용하면

**set1 = {a} , set2 = {b}, set3 = {c} , set4 = {d}, set5 = {e} , set6 = {f}** 로 데이터를 집합으로 나눈 후,

**시행 1 : 훈련 세트 = set1, set2, set3, set4, set5 / 시험 세트 = set6**

**시행 2 : 훈련 세트 = set1, set2, set3, set4, set6 / 시험 세트 = set5**

**시행 3 : 훈련 세트 = set1, set2, set3, set5, set6 / 시험 세트 = set4**

**시행 4 : 훈련 세트 = set1, set2, set4, set5, set6 / 시험 세트 = set3**

**시행 5 : 훈련 세트 = set1, set3, set4, set5, set6 / 시험 세트 = set2**

**시행 6 : 훈련 세트 = set2, set3, set4, set5, set6 / 시험 세트 = set1**

그 후 n번의 시행으로 얻은 n개의 성능 점수를 평균화 합니다.

<br>

# 이들의 차이

---

그렇다면 저희는 모델 성능을 평가할 때 어떤 방법을 사용해야 할까요?
위 예시를 통해 보셨다면 유추하실 수 있겠지만, **보통 leave-one-out이 단 하나의 세트를 시험 세트로 이용하기 때문에 시행이 더 많습니다.**

**따라서 만약 데이터 세트의 크기가 작다면? leave-one-out이 더 적합할 수 있습니다.**

**반대로 데이터 세트가 많다면 leave-one-out의 방법을 모델을 훈련하는 시간이 너무 오래걸릴 수 있습니다. 또한, 충분히 많은 데이터라면 굳이 n개로 세트를 나누는 것보다 적은 수인 k(n < k)로 나누는 것도 충분한 결과를 내기 때문에 k-fold가 좋은 방법일 수 있습니다.**
