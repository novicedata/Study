---
excerpt: "교차검증을 알아보자"

categories:
  - Resampling

tags:
  - [통계 분석]

toc: true
toc_sticky: true

breadcrumb: true

date: 2023-09-16
last_modified_at: 2023-09-16

title: "교차 검증 : Hold-out, Leave-one-out, K-fold"
---
<br>

**`아래에서 설명하는 내용은 모두 Train set를 이미 따로 둔 상태를 가정하고 설명하는 겁니다.`**

<br>

# 📌 Hold-out
---

**`Hold-out`**방법의 경우 간단합니다. 보통 50:50을 사용하고 주어진 데이터를 랜덤하게 Train set, Validation set로 나눕니다.

![image](https://github.com/novicedata/colab_practice/assets/88019539/9acae7c7-e562-44d1-8ade-37591911a7b9){: .align-center}

## `with R`

```r
# Auto data의 mpg 사용.


library(ISLR)
set.seed(42)

data = Auto$mpg
dim(data.frame(data))
>> 392 1 
```

```r
# caret이용
library(caret)
train = createDataPartition(data, p=0.5)
dim(data.frame(train))
>> 198 1
```

**`10번 해보기`**

```r
for (i in 1:10) {
  set.seed(i) # 시드 변경하며 보기
  train = createDataPartition(data,p=0.5, list=FALSE)
  MSE = rep(0:10) # error 저장할 영벡터 길이 0
  
  for (j in 1:10) {
    fit = lm(mpg ~ poly(horsepower, j), data=Auto,
             subset = train)
    MSE[j] = mean((Auto$mpg[-train]-predict(fit, Auto[-train,]))^2)
  }
  if (i == 1) {
    plot(MSE, ylab='MSE', xlab='다항회귀 차수')
    
  } else {
    lines(MSE, col=i)
  }
}
```

![image](https://github.com/novicedata/colab_practice/assets/88019539/823ac975-1469-4fb3-9c90-4a066f211b8f){: .align-center}

다항 함수로 해본 예시 입니다. 2차항부터 대략 9차항까지 MSE의 차이가 없는 걸 보니 validaition set로 본 결과 2차항까지만 사용해서 test set으로 성능을 확인하면 될 것같네요.

<br>

# 📌 Leave-One-Out Cross-validation
---

**`LOOCV`**. 이해하기 굉장히 쉽습니다. 데이터가 n개 있다고 할 때. n-1개를 랜덤으로 뽑아 train set를 만들고 나머지 1개를 validation set로 이용하는 것입니다. 단점이라면 데이터가 커질수록 Train, Test set로 split한 set가 많아진다는 거죠. 그만큼 컴퓨팅 자원이 많이 듭니다.

![image](https://github.com/novicedata/colab_practice/assets/88019539/850e0187-2bfc-4fb0-aa73-e7e5eb12c075){: .align-center}

**`error 계산`**

$$
MSE_i = (y_i-\hat{y}_i)^2
$$

일때 leave one out cv를 사용한 test error는 아래와 같습니다.

$$
LOO_{e(n)} = \frac1n \sum^n_{i=1}MSE_i
$$

## `with R`

똑같이 mpg를 이용합니다.

```r
library(boot)

MSE = rep(0,10) 
for (i in 1:10) {
  fit = glm(mpg~poly(horsepower, i), data=Auto)
  MSE[i]= cv.glm(Auto, fit)$delta[1] # LOOCV 수행 후 MSE 추출
  
  plot(MSE, type='o', xlab='차수', col='blue')
}
```

![image](https://github.com/novicedata/colab_practice/assets/88019539/c9d0aef5-c4be-4480-a5a5-f899617660a7){: .align-center}

<br>

# 📌 k-fold Cross-validation
---

**`k-fold`**입니다. 위에서 LOOCV의 경우 데이터가 크면 클수록 컴퓨팅 자원이 많이 든다는 단점이 있었죠(실제로 데이터를 다루다보면 잘못씁니다..) 그래서 **n개의 데이터에서 n-1개로 train set를 만드는게 아니라 원하는 개수의 fold로 만들어 나눕니다.**

아래 그림은 **4-fold 예시입니다.**

![image](https://github.com/novicedata/colab_practice/assets/88019539/beee783d-f6b7-482c-aec0-c589b9a55ad0){: .align-center}

**`error 계산`**

$$
Fold_{e(k)} = \frac1k \sum^k_{i=1}MSE_i
$$

## `with R`

```r
set.seed(15)
k =10
MSE_matrix = matrix(0, nrow=k, ncol=10)
folds <- sample(1:k, length(Auto$mpg), replace = T, prob=rep(1/k,k))

for (i in 1:k) {
  for (j in 1:10) {
    fit = lm(mpg~poly(horsepower,j), data = Auto[folds != i, ])
    pred = predict(fit, newdata=Auto[folds == i,])
    MSE_matrix[i,j] = mean((pred-Auto$mpg[folds == i])^2)
  }
  if (i == 1) {
    plot(MSE, type = 'l', xlab='차수', ylab='MSE')
  } else {
    lines(MSE_matrix[i,], type = 'l', col=i)
  }
}
```

![image](https://github.com/novicedata/colab_practice/assets/88019539/a08c2a61-ac32-4f98-871b-0fba4cd2922b){: .align-center}

그래프를 보시면 맨처음 Hold-out과 비슷하게 2차에서 비슷해지는 경향이 있습니다. 코드를 돌려보시면 아시겠지만 이게 seed값을 변경해줄 때마다 MSE 값 차이가 좀 있습니다. 그래서 정확히 보려면 시간이 걸리더라도 LOOCV가 좋을수도 있습니다.
