

ğŸ“Œ Gradient Boosting Gradient Boostingì€ Gradient descentì™€ boostingì„ í•©ì¹œ ê²ƒìœ¼ë¡œ, ê²½ì‚¬í•˜ê°•ë²•ê³¼ ë¶€ìŠ¤íŒ… ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê²½ì‚¬í•˜ê°•ë²•ì—ì„œ lossì¸ $L(\\theta)$ë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ $\\theta$

datanovice.tistory.com](https://datanovice.tistory.com/entry/2-Boosting-Gradient-Boosting%EC%99%9C-Gradient%EC%9D%B8%EA%B0%80)

ì²œì²œíˆ ì‹œì‘í•´ ë´…ì‹œë‹¤.

## ğŸ“Œ ìµœì í™”í•´ì•¼ í•˜ëŠ” ëª©ì  í•¨ìˆ˜

**ìš°ë¦¬ê°€ ìµœì í™”í•´ì•¼ í•˜ëŠ” ëª©ì  í•¨ìˆ˜ëŠ” ì†ì‹¤í•¨ìˆ˜ì™€ ì •ê·œí™”í•­ì˜ í•©ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê³  ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ $\\theta$ëŠ” ìš°ë¦¬ê°€ ì¶”ì •í•´ì•¼ í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤.**

$$  
F(\\theta) = L(\\theta) + \\Omega(\\theta)  
$$

ì—¬ê¸°ì„œ ì†ì‹¤í•¨ìˆ˜ì¸ $L(\\theta)$ëŠ” íšŒê·€ì˜ ê²½ìš° ê°€ì¥ í”í•œ square loss functionì´ ë  ìˆ˜ë„ ìˆê³ , ë¶„ë¥˜ì˜ ê²½ìš° logistic loss functionì´ ë  ìˆ˜ë„ ìˆê² ë„¤ìš”.

### 1\. ì†ì‹¤ í•¨ìˆ˜ ì •ë¦¬

#### â—¼ï¸ ê°€ë²• ëª¨í˜•

ë¶€ìŠ¤íŒ… ëª¨ë¸ì€ ì—¬ëŸ¬ ì•½í•œ í•™ìŠµê¸°ë¥¼ ë”í•´ ê°•í•˜ê²Œ ë§Œë“œëŠ” ê²ƒì´ë¼ê³  í–ˆìŠµë‹ˆë‹¤. **ì´ë ‡ë“¯ ë¶€ìŠ¤íŒ… ëª¨ë¸ì€ í•˜ë‚˜ì˜ ê°€ë²• ëª¨í˜•ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

$$  
\\hat{y}\_i = \\sum\_{k=1}^K f\_k(\\textbf{x}\_i)  
\\ where \\ f\_k \\in \\mathcal{F}  
$$

ì˜ˆì¸¡ê°’ $\\hat{y}$ëŠ” ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ $f\_k(\\textbf{x}\_i)$ì˜ í•©ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.

ì´ë¥¼ ë‚˜ë¬´ $t$ì˜ ë‹¨ê³„ì— ë”°ë¼ ì¨ë³¸ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì„ ê²ë‹ˆë‹¤.

$$  
\\begin{align\*} \\hat{y}i^0 &= 0  
\\\\ \\hat{y}\_i^1 &= \\hat{y}\_i^0 + f\_1(\\mathbf{x}\_i) = f\_1(\\mathbf{x}\_i)  
\\\\ \\hat{y}\_i^2 &= \\hat{y}\_i^1 + f\_2(\\mathbf{x}\_i) = f\_2(\\mathbf{x}\_i) + f\_1(\\mathbf{x}\_i)  
\\\\ &\\vdots  
\\\\ \\hat{y}\_i^t &= \\hat{y}\_i^{t-1} + f\_t(\\mathbf{x}\_i) = \\sum\_{k=1}^t f\_k(\\mathbf{x}\_i)  
\\end{align\*}  
$$

ê·¸ëŸ¼ ì´ ê°€ë²• ëª¨í˜•ì„ í†µí•´ $t$ë²ˆì§¸ ëª¨ë¸ì—ì„œì˜ ëª©ì í•¨ìˆ˜ë¥¼ ë´…ì‹œë‹¤.

$$  
\\begin{align}  
F(\\theta)^t &= \\sum\_{i=1}^n l(y\_i, \\hat{y}\_i^t) + \\sum\_{k=1}^K \\omega (f\_k)  
\\\\ &= \\sum\_{i=1}^n l(y\_i, \\hat{y}\_i^{t-1} + f\_t(\\textbf{x}\_i)) + \\omega(f\_t) + constant  
\\end{align}  
$$

#### â—¼ï¸ í…Œì¼ëŸ¬ ê¸‰ìˆ˜

**í…Œì¼ëŸ¬ ê¸‰ìˆ˜**ë¥¼ ì´ìš©í•´ ë´…ì‹œë‹¤. **ì†ì‹¤í•¨ìˆ˜ë¥¼ ì‰¬ìš´ ê²ƒì„ ì‚¬ìš©í•˜ë©´ ê³„ì‚°ì‹ë„ ì‰½ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ loss squre functionì˜ ê²½ìš° ì‹ì´ êµ‰ì¥íˆ ê°„ë‹¨í•˜ì£ . í•˜ì§€ë§Œ ë‹¤ë¥¸ functionì˜ ê²½ìš° ì‹ì´ ë§¤ìš° ê³„ì‚°í•˜ê¸° ë³µì¡í•˜ê³  ì–´ë ¤ì›Œ ì§‘ë‹ˆë‹¤. ê·¸ë˜ì„œ í…Œì¼ëŸ¬ ê¸‰ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤ê³  í•©ë‹ˆë‹¤.**(ì œê°€ ì•Œê¸°ë¡  ê·¸ë ‡ìŠµë‹ˆë‹¤ë§Œ í‹€ë ¸ë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”.)

í•œë²ˆ ë´…ì‹œë‹¤. ì•„ë˜ì™€ ê°™ì´ $g\_i, h\_i$ë¥¼ ì •ì˜í–ˆì„ ë•Œ(í…Œì¼ëŸ¬ 1ì°¨ì‹, 2ì°¨ì‹)

$$  
g\_i = \\dfrac{\\partial}{\\partial \\hat{y}^{t-1}}l(y\_i, \\hat{y}^{t-1})  
\\ h\_i = (\\dfrac{\\partial}{\\partial \\hat{y}^{t-1}})^2 l(y\_i, \\hat{y}^{t-1})  
$$

ëª©ì  í•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ì•„ì§‘ë‹ˆë‹¤.

$$  
\\begin{align}  
F(\\theta)^t = \\sum\_{i=1}^n\[l(y\_i, \\hat{y}\_i^{t-1}) + g\_i f\_t(\\textbf{x}\_i) + \\frac12 h\_i f\_t^2(\\textbf{x}\_i)\] + \\omega(f\_t) + constant  
\\end{align}  
$$

ì—¬ê¸°ì„œ ìƒìˆ˜ë“¤ì„ ì œê±°í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ì‹ì„ ì–»ê²Œ ë˜ë„¤ìš”.

$$  
\\begin{align}  
F(\\theta)^t = \\sum\_{i=1}^n\[ g\_i f\_t(\\textbf{x}\_i) + \\frac12 h\_i f\_t^2(\\textbf{x}\_i)\] + \\omega(f\_t)  
\\end{align}  
$$

### 2\. ì •ê·œí™”í•­ ì •ë¦¬

**ì´ë²ˆì—” ì •ê·œí™”í•­ì„ ì •ë¦¬í•´ ë´…ì‹œë‹¤.**

#### â—¼ï¸ final nodes

fë¥¼ $T$ê°œì˜ final nodes(treeì˜ ë§¨ ì•„ë˜ node)ë¡œ ì´ë£¨ì–´ì§„ íŠ¸ë¦¬ë¼ê³  í•  ë•Œ

$$  
f(x) = w\_{q(x)}  
$$

ì •ê·œí™”í•­ $\\omega(f)$ëŠ” ì•„ë˜ì™€ ê°™ë‹¤ê³  í•©ë‹ˆë‹¤.

$$  
\\omega(f) = \\gamma T + \\frac12 \\lambda \\sum\_{j=1}^T w\_j^2  
$$

**ê·¸ëŸ¼ ìœ„ì—ì„œ ì •ì˜í•œ ë‘ì‹ $f(x), \\omega(f)$ë¥¼ ì‹(9)ì— ëŒ€ì…í•´ ë´…ì‹œë‹¤.**

$$  
\\begin{align}  
F(\\theta)^t = \\sum\_{i=1}^n\[ g\_i w\_{q(\\textbf{x}\_i)} + \\frac12 h\_i w^2\_{q(\\textbf{x}\_i)}\] + \\gamma T + \\frac12 \\lambda \\sum\_{j=1}^T w\_j^2  
\\end{align}  
$$

### 3\. whole form

**ì´ì–´ì„œ $t$ë²ˆì§¸ íŠ¸ë¦¬ì—ì„œ, $I = { i:q(\\textbf{x}\_i)=j }$ë¥¼ $j$ë²ˆì§¸ final nodeì— ì†í•˜ëŠ” ì¸ë±ìŠ¤ ì§‘í•©ì´ë¼ê³  í•©ì‹œë‹¤.**

**ì—¬ê¸°ì„œ $G\_j = \\sum\_{i \\in I\_j} g\_i, H\_j = \\sum\_{i \\in I\_j} h\_i$ë¼ í•˜ê³  ì‹(10)ì— ëŒ€ì…í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.**

$$  
\\begin{align}  
F(\\theta)^t &= \\sum\_{j=1}^T\[ (\\sum\_{i \\in I\_j}g\_i) w\_j + \\frac12 (\\sum\_{i \\in I\_j}h\_i + \\lambda) w\_j^2\] + \\gamma T  
\\\\ & = \\sum\_{j=1}^T\[ G\_j w\_j + \\frac12 (H\_j + \\lambda) w\_j^2\] + \\gamma T  
\\end{align}  
$$

ì´ë•Œ íŠ¸ë¦¬ êµ¬ì¡° $q$ì— ë”°ë¼ ìµœì ì˜ $w\_j$ë¥¼ ì•„ë˜ì™€ ê°™ì´ ì •ì˜í•˜ë©´

$$  
w\_j = -\\dfrac{G\_j}{H\_j+\\lambda}  
$$

ìµœì¢… ëª©ì í•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$  
\\begin{align}  
F(\\theta)^t & = -\\frac12 \\sum\_{j=1}^T \\dfrac{G\_j^2}{H\_j +\\lambda} + \\gamma T  
\\end{align}  
$$

## ğŸ“Œ í•™ìŠµ

ì. ì‹ì€ ë‚˜ì™”ê³  ê·¸ëŸ¼ í•™ìŠµì€ ì–´ë–»ê²Œ í• ê¹Œìš”??

ìš°ë¦¬ê°€ í•˜ë‚˜ì˜ nodeì—ì„œ í•˜ìœ„ ë‘ ê°œì˜ nodeë¡œ ë¶„ë¦¬í•  ë•Œ ì•„ë˜ì™€ ê°™ì€ Gain í•¨ìˆ˜ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$  
G\_{split} = \\frac{1}{2} \\left\[\\frac{G\_L^2}{H\_L+\\lambda}+\\frac{G\_R^2}{H\_R+\\lambda}-\\frac{(G\_L+G\_R)^2}{H\_L+H\_R+\\lambda}\\right\] - \\gamma  
$$

ì‹ì˜ êµ¬ì¡°ë¥¼ ë³´ë©´ ë¶„í•  í›„ì˜ ì™¼ìª½ node, ì˜¤ë¥¸ìª½ nodeì— í•´ë‹¹í•œ ê°’ì„ ë”í•œ ë’¤, ì „ì²´ nodeì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ëº´ì¤ë‹ˆë‹¤.

**ìœ„ $G\_{split}$ê°’ì´ í¬ë‹¤ëŠ” ê²ƒì€ ë¶„í•  í›„ì˜ ê°’ì´ í¬ë‹¤ëŠ” ê²ƒìœ¼ë¡œ! ì´ ê°’ì„ ìµœëŒ€í™”í•  ë•Œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì ì˜ ë¶„í• ì„ ì°¾ìŠµë‹ˆë‹¤.**
