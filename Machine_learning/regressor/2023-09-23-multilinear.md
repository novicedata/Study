---

excerpt: "Rê³¼ pythonìœ¼ë¡œ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¥¼ í•´ë³´ì."

categories:

- Machine learning

tags:

- [íŒŒì´ì¬, R]

toc: true
toc_sticky: true

breadcrumb: true

date: 2023-09-23
last_modified_at: 2023-09-23

title: "[Machine learning] ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ì˜ˆì œ with R, Python"

---

<br>

ì´ë²ˆì—” ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¥¼ Rê³¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ìµœê·¼ì—” ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì´ ì •ë§ ë‹¨ìˆœí•œ ëª¨ë¸ì´ ë˜ì—ˆì£ .

ê°„ë‹¨í•œ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ì— ëŒ€í•œ ì„¤ëª…ì€ ì•„ë˜ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.

- [ë‹¤ì¤‘ ì„ í˜•íšŒê·€ - ë°ì´í„° ë…¸íŠ¸ ğŸ“](https://novicedata.github.io/statistical%20learning/%EB%8B%A4%EC%A4%91-%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80/)
  

<br>

# â—¾ With Python

---

## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```python
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes

data = load_diabetes()
data.keys()
```

sklearnì˜ diabetes ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ê² ìŠµë‹ˆë‹¤. êµ¬ì¡°ë¥¼ í•œë²ˆ ë´…ì‹œë‹¤.

## X,y ë¡œ ë‚˜ëˆ„ê¸°

```python
X = pd.DataFrame(data['data'], columns=data['feature_names'])
y = pd.DataFrame(data['target'], columns=['target'])
X
```

![image](https://github.com/novicedata/baekjoon/assets/88019539/1339954b-ff55-4ec3-ad8b-bbe6275ce08e){: .align-center}

## Train, Test set 8:2ë¡œ ë‚˜ëˆ„ê¸°

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)
```

## model fitting í•˜ê¸°

```python
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)
```

## intercept, coefê°’ í™•ì¸í•˜ê¸°

```python
print(model.intercept_, model.coef_)
> [151.34560454] 
  [[37.90402135 -241.96436231  542.42875852  347.70384391 -931.48884588
   518.06227698  163.41998299  275.31790158  736.1988589    48.67065743]]
```

## ì‹œê°í™” í•´ë³´ê¸°

```python
# ê²€ì€ì„ ì€ ì‹¤ì œ yê°’, ë¹¨ê°„ì„ ì€ modelë¡œ ì˜ˆì¸¡í•œ yê°’ ì…ë‹ˆë‹¤.
# ê°ê° ì•ì—ì„œ 80ê°œì˜ ê°’ë§Œ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.
fig = plt.figure(figsize=(20,4))
graph = fig.add_subplot(1,1,1)
graph.plot(y[:80], color='black', marker='o', label='real y values')
graph.plot(model.predict(X)[:80], marker='^', color='red', label='prediction')
plt.legend(loc='best')
plt.show()
```

![image](https://github.com/novicedata/baekjoon/assets/88019539/5f4ceadc-4d1f-41e6-a60b-27a42f78aad2){: .align-center}

<br>

# â—¾ with R

---

## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```r
# import
library(MASS)
Boston
```

MASS ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Boston ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.

## Train, Test set 8:2ë¡œ ë‚˜ëˆ„ê¸°

```r
# Train set, Test setìœ¼ë¡œ ë‚˜ëˆ„ê¸°(8:2)
library(caTools)
set.seed(42)
split = sample.split(Boston$medv, SplitRatio=0.8)
train = subset(Boston, split==T)
test = subset(Boston, split==F)
```

## model fitting í•˜ê¸°

```r
# Fitting ëª¨ë¸
model = lm(medv~., data=train)

summary(model)
```

![image](https://github.com/novicedata/baekjoon/assets/88019539/d6d0498c-6cda-482f-96a4-3a034bfbacb6){: .align-center}

Rì€ ì´ê²Œ ì°¸ ì¢‹ì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤ **summaryë©´ ë‹¤ ë³¼ ìˆ˜ ìˆëŠ”..** ê° p-valueì™€ estimateë„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì‹œê°í™” í•´ë³´ê¸°

```r
# ì‹œê°í™”
library(ggplot2)

ggplot() +
  geom_line(aes(x = (1:length(test$medv)), y = test$medv, color = 'Real'), size = 1) +
  geom_line(aes(x = (1:length(y_pred)), y = y_pred, color = 'Prediction'), size = 1) +
  scale_color_manual(values = c('Real' = 'black', 'Prediction' = 'red'),
                     labels = c('Prediction', 'Real')) +
  labs(color = 'Line') +
  theme_bw() +
  xlab('x') +
  ylab('medv') +
  theme(legend.position = c(0.1,0.9))
```

![image](https://github.com/novicedata/baekjoon/assets/88019539/4da797c4-271d-4d8d-9af1-82122f798f88){: .align-center}
